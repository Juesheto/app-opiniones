# -*- coding: utf-8 -*-
"""app.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1l40RvSshFvU48kD-swBq35wrMKlyAqBn
"""


import nltk
nltk.download('stopwords')

import pandas as pd

opiniones = [
    "El producto lleg√≥ en mal estado y no funciona.",
    "Excelente servicio, me encant√≥ todo.",
    "La atenci√≥n al cliente fue regular.",
    "Volver√≠a a comprar sin duda.",
    "Muy demorado el env√≠o.",
    "Me encant√≥, s√∫per recomendado.",
    "Mala calidad, no lo recomiendo.",
    "La experiencia fue neutral.",
    "No fue lo que esperaba, pero tampoco estuvo mal.",
    "Muy buen producto.",
    "El empaque ven√≠a roto.",
    "Todo bien, sin problemas.",
    "No lleg√≥ lo que ped√≠.",
    "R√°pido y eficiente.",
    "Nada especial, regular.",
    "La presentaci√≥n fue excelente.",
    "Tuve que devolverlo.",
    "Funcion√≥ perfectamente.",
    "La descripci√≥n no coincide con el producto.",
    "Muy satisfecho con la compra."
]

df = pd.DataFrame({'opinion': opiniones})

from nltk.corpus import stopwords
import string

stop_words = set(stopwords.words('spanish'))

def limpiar_texto(texto):
    texto = texto.lower().translate(str.maketrans('', '', string.punctuation))
    tokens = texto.split()
    tokens = [word for word in tokens if word.isalpha() and word not in stop_words]
    return tokens

df['tokens'] = df['opinion'].apply(limpiar_texto)

from wordcloud import WordCloud
import matplotlib.pyplot as plt
from collections import Counter

# Concatenar todos los tokens
todos_los_tokens = sum(df['tokens'].tolist(), [])

# Nube de palabras
wordcloud = WordCloud(width=800, height=400, background_color='white').generate(' '.join(todos_los_tokens))
plt.figure(figsize=(10, 5))
plt.imshow(wordcloud, interpolation='bilinear')
plt.axis('off')
plt.title("Nube de Palabras")
plt.show()

# Top 10 palabras m√°s frecuentes
contador = Counter(todos_los_tokens)
palabras_comunes = contador.most_common(10)
palabras, frecuencias = zip(*palabras_comunes)

plt.figure(figsize=(10,5))
plt.bar(palabras, frecuencias)
plt.title("Top 10 Palabras M√°s Frecuentes")
plt.ylabel("Frecuencia")
plt.xticks(rotation=45)
plt.show()

from transformers import pipeline

# Cargar modelo de sentimiento multiling√ºe
clasificador = pipeline("sentiment-analysis", model="nlptown/bert-base-multilingual-uncased-sentiment")

def clasificar_sentimiento_mejorado(texto):
    texto = texto.lower()

    frases_positivas = [
        'excelente', 'me encant√≥', 'muy buen', 'recomendado', 'volver√≠a a comprar',
        'satisfecho', 'perfectamente', 'funcion√≥', 'eficiente', 'todo bien', 'sin problemas'
    ]

    frases_negativas = [
        'no funciona', 'mal estado', 'muy demorado', 'devolverlo', 'no lleg√≥',
        'mala calidad', 'no lo recomiendo', 'empaque ven√≠a roto',
        'no fue lo que esperaba', 'coincide con el producto'
    ]

    positivo = any(frase in texto for frase in frases_positivas)
    negativo = any(frase in texto for frase in frases_negativas)

    if positivo and not negativo:
        return 'Positivo'
    elif negativo and not positivo:
        return 'Negativo'
    elif positivo and negativo:
        return 'Neutro'
    else:
        return 'Neutro'

df['sentimiento'] = df['opinion'].apply(clasificar_sentimiento_mejorado)


print(df[['opinion', 'sentimiento']])

# Gr√°fico
import matplotlib.pyplot as plt
df['sentimiento'].value_counts().plot(kind='pie', autopct='%1.1f%%', figsize=(6, 6), title='Distribuci√≥n de Sentimientos')
plt.ylabel("")
plt.show()

"""Parte 2"""

# Analiza un comentario nuevo con sentimiento + resumen
nuevo_comentario = input("üìù Escribe un nuevo comentario para analizar: ")

# Clasificar sentimiento
sentimiento = clasificador(nuevo_comentario)[0]
estrellas = int(sentimiento['label'][0])
if estrellas <= 2:
    resultado_sentimiento = 'Negativo'
elif estrellas == 3:
    resultado_sentimiento = 'Neutro'
else:
    resultado_sentimiento = 'Positivo'

# Resumen usando modelo multiling√ºe ingl√©s
resumidor = pipeline("summarization", model="facebook/bart-large-cnn")
resumen = resumidor(nuevo_comentario, max_length=50, min_length=10, do_sample=False)[0]['summary_text']

# Mostrar resultado
print(f"\nüìå Clasificaci√≥n de sentimiento: {resultado_sentimiento}")
print(f"üßæ Resumen del comentario: {resumen}")

from collections import Counter

opcion = input("¬øQu√© quieres ver? (resumen / temas): ").strip().lower()

if opcion == "resumen":
    texto_completo = "\n".join(df['opinion'].tolist())[:1024]
    resumen = resumidor(texto_completo, max_length=130, min_length=30, do_sample=False)[0]['summary_text']
    print("\nüìÑ Resumen general de los comentarios:")
    print(resumen)

elif opcion == "temas":
    todos_los_tokens = sum(df['tokens'].tolist(), [])
    temas_comunes = Counter(todos_los_tokens).most_common(5)
    print("\nüí¨ Temas m√°s discutidos:")
    for palabra, frecuencia in temas_comunes:
        print(f"- {palabra} ({frecuencia} veces)")
else:
    print("‚ùå Opci√≥n no v√°lida. Escribe 'resumen' o 'temas'.")

